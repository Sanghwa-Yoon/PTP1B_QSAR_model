{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a7a666e",
   "metadata": {},
   "source": [
    "\n",
    "# Descriptor Preprocessing\n",
    "\n",
    "This notebook performs preprocessing on calculated molecular descriptors, including:\n",
    "1. Handling missing values by imputing with the mean.\n",
    "2. Removing low-variance features.\n",
    "3. Removing highly correlated features.\n",
    "\n",
    "The final preprocessed data is saved for further use in QSAR modeling.\n",
    "\n",
    "---\n",
    "### Inputs and Outputs:\n",
    "- **Inputs**:\n",
    "  - `posi_descriptor.csv` (Positive descriptors with label `1`)\n",
    "  - `nega_descriptor.csv` (Negative descriptors with label `0`)\n",
    "- **Output**:\n",
    "  - `Descriptor_preprocessing_results.csv` (Preprocessed descriptors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001b44a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Import Libraries and Load Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load data\n",
    "po_data = pd.read_csv('posi_descriptor.csv')\n",
    "ne_data = pd.read_csv('Nega_descriptor.csv')\n",
    "\n",
    "print(f\"Positive data shape: {po_data.shape}\")\n",
    "print(f\"Negative data shape: {ne_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ce85e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Impute Missing Values and Add Labels\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# Process positive data\n",
    "imp.fit(po_data)\n",
    "df_posi = pd.DataFrame(imp.transform(po_data), columns=po_data.columns)\n",
    "df_posi['y_label'] = 1\n",
    "\n",
    "# Process negative data\n",
    "imp.fit(ne_data)\n",
    "df_nega = pd.DataFrame(imp.transform(ne_data), columns=ne_data.columns)\n",
    "df_nega['y_label'] = 0\n",
    "\n",
    "# Concatenate positive and negative datasets\n",
    "df_concat = pd.concat([df_posi, df_nega])\n",
    "\n",
    "# Separate features and labels\n",
    "x_data = df_concat.drop(columns=['y_label'])\n",
    "y_data = df_concat['y_label']\n",
    "\n",
    "print(f\"Combined data shape: {x_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc443051",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Remove Low-Variance Features\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "sel = VarianceThreshold(threshold=0.01)\n",
    "featuredDataSet = sel.fit_transform(x_data)\n",
    "\n",
    "# Create DataFrame for selected features\n",
    "X_selected_df = pd.DataFrame(featuredDataSet, columns=[x_data.columns[i] for i in range(len(x_data.columns)) if sel.get_support()[i]])\n",
    "\n",
    "print(\"============================================\")\n",
    "print(\"After Removing Low-Variance Features\")\n",
    "print(\"============================================\")\n",
    "print(X_selected_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62622ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Remove Highly Correlated Features\n",
    "corr_table = X_selected_df.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_table.where(np.triu(np.ones(corr_table.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find columns with correlation > 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "# Drop highly correlated features\n",
    "X_corr_df = X_selected_df.drop(to_drop, axis=1)\n",
    "\n",
    "print(\"============================================\")\n",
    "print(\"After Removing Highly Correlated Features\")\n",
    "print(\"============================================\")\n",
    "print(X_corr_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04262ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 5: Save Final Preprocessed Data\n",
    "# Add 'y_label' back to the preprocessed data\n",
    "# Reset index for both X_corr_df and y_data to ensure alignment\n",
    "X_corr_df = X_corr_df.reset_index(drop=True)\n",
    "y_data = pd.Series(y_data, name='y_label').reset_index(drop=True)\n",
    "\n",
    "# Concatenate X_corr_df and y_data\n",
    "final_data_with_label = pd.concat([X_corr_df, y_data], axis=1)\n",
    "\n",
    "# Save the final data with labels\n",
    "final_data_with_label.to_csv('Descriptor_preprocessing_results.csv', index=False)\n",
    "print(\"Preprocessed data with labels saved to Descriptor_preprocessing_results.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
