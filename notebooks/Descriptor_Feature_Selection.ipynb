{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40224507",
   "metadata": {},
   "source": [
    "\n",
    "# Feature Selection\n",
    "\n",
    "This notebook performs feature selection on the preprocessed molecular descriptors using Logistic Regression with L1 regularization.\n",
    "\n",
    "### Steps:\n",
    "1. Load preprocessed descriptor data from `Descriptor_preprocessing_results.csv`.\n",
    "2. Perform feature selection over 100 iterations.\n",
    "3. Summarize the frequency of feature selection.\n",
    "4. Identify and save the most frequently selected features.\n",
    "\n",
    "---\n",
    "### Inputs and Outputs:\n",
    "- **Input**:\n",
    "  - `Descriptor_preprocessing_results.csv` (Preprocessed descriptors)\n",
    "- **Outputs**:\n",
    "  - `00_feature_selection_df.csv` (Frequency of feature selection for all features)\n",
    "  - List of most frequently selected features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ebca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Import Libraries and Load Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load preprocessed descriptor data\n",
    "pre_data_df = pd.read_csv('Descriptor_preprocessing_results.csv')\n",
    "\n",
    "# Separated x_data and y_data\n",
    "x_data = pre_data_df.drop(columns=['y_label'])\n",
    "y_data = pre_data_df['y_label']\n",
    "\n",
    "print(f\"Loaded data shape: {pre_data_df.shape}\")\n",
    "print(f\"Target variable shape: {len(y_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106a1bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Perform Feature Selection\n",
    "# Dictionary to store the count of how many times each feature is selected\n",
    "feature_selection_counts = {feature: 0 for feature in x_data.columns}\n",
    "\n",
    "# Perform 100 iterations\n",
    "for _ in range(100):\n",
    "    # Create a new logistic regression model with L1 penalty\n",
    "    logreg = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "    \n",
    "    # Train the model\n",
    "    logreg.fit(x_data, y_data)\n",
    "    \n",
    "    # Update feature_selection_counts based on which features were selected (non-zero coefficients)\n",
    "    selected_features = x_data.columns[logreg.coef_[0] != 0]\n",
    "    for feature in selected_features:\n",
    "        feature_selection_counts[feature] += 1\n",
    "\n",
    "print(\"Feature selection completed over 100 iterations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c9ae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Analyze Feature Selection Results\n",
    "# Convert the dictionary to a DataFrame for easier analysis and visualization\n",
    "feature_selection_df = pd.DataFrame.from_dict(feature_selection_counts, orient='index', columns=['Selection Count'])\n",
    "\n",
    "# Sort the DataFrame to see the most frequently selected features\n",
    "feature_selection_df = feature_selection_df.sort_values(by='Selection Count', ascending=False)\n",
    "\n",
    "# Summarize the frequency of feature selection\n",
    "summary_df = feature_selection_df['Selection Count'].value_counts().reset_index()\n",
    "summary_df.columns = ['Selection Count', 'Number of Descriptors']\n",
    "summary_df = summary_df.sort_values(by='Selection Count', ascending=True)\n",
    "\n",
    "print(\"Feature selection summary:\")\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e81af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Extract Most Frequently Selected Features\n",
    "Final_feature_selection_df = feature_selection_df[feature_selection_df['Selection Count'] == 100]\n",
    "Final_features = Final_feature_selection_df.index.tolist()\n",
    "\n",
    "print(f\"Number of features selected in all 100 iterations: {len(Final_features)}\")\n",
    "print(\"Most frequently selected features:\")\n",
    "print(Final_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02c91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 5: Save Final Features and Extract Relevant Data\n",
    "\n",
    "# Save the most frequently selected features to a text file\n",
    "with open('Final_selected_descriptor_list.txt', 'w') as f:\n",
    "    for feature in Final_features:\n",
    "        f.write(f\"{feature}\\n\")\n",
    "print(\"Final features saved to Final_selected_descriptor_list.txt\")\n",
    "\n",
    "# Extract relevant data based on Final_features and add y_data\n",
    "Final_feature_selection_data = pre_data_df[Final_features].copy()\n",
    "Final_feature_selection_data['y_label'] = y_data\n",
    "\n",
    "# Save the data to a CSV file\n",
    "Final_feature_selection_data.to_csv('Final_feature_selection_data_with_ylabel.csv', index=False)\n",
    "print(\"Final feature selection data saved to Final_feature_selection_data_with_ylabel.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
